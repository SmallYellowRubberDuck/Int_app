{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sec</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>akn00006_fqGg6dtL</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akn00006_fqGg6dtL</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>akn00006_fqGg6dtL</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akn00006_fqGg6dtL</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>akn00006_fqGg6dtL</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                file  sec  label\n",
       "0  akn00006_fqGg6dtL   18      1\n",
       "1  akn00006_fqGg6dtL   75      4\n",
       "2  akn00006_fqGg6dtL  249      1\n",
       "3  akn00006_fqGg6dtL  250      2\n",
       "4  akn00006_fqGg6dtL  263      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"df_train.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n",
    "labels = {\n",
    "    \"Нет\": 0,\n",
    "    \"12.16. часть 1\": 1,\n",
    "    \"12.17\": 2,\n",
    "    \"12.12\": 3,\n",
    "    \"12.15\": 4,\n",
    "    \"12.16 часть 2\": 4\n",
    "}\n",
    "\n",
    "def apply_label(text):\n",
    "    for key, value in labels.items():\n",
    "        if key in text:\n",
    "            return value\n",
    "    return 0 \n",
    "\n",
    "df.drop(columns=[\"сумма штрафа, руб.\"], inplace=True)\n",
    "df['label'] = df['наименование нарушения'].apply(apply_label)\n",
    "df.drop(columns=['наименование нарушения'], inplace=True)\n",
    "df.rename(columns={\"время нарушения (в секундах)\": \"sec\", \"номер видео\": \"file\"}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime-silicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 06:35:57.647273 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_16_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:57.647437 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_15_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:57.647785 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_11_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:57.647843 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_10_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:57.648113 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_6_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:57.648153 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_5_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:57.708046 [W:onnxruntime:, coreml_execution_provider.cc:81 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 15 number of nodes in the graph: 430 number of nodes supported by CoreML: 299\n",
      "2024-11-10 06:35:59.123500 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2024-11-10 06:35:59.123514 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n",
      "2024-11-10 06:35:59.163469 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_16_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:59.163505 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_15_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:59.163733 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_11_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:59.163758 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_10_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:59.163984 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_6_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:59.164008 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. '/model.22/Unsqueeze_5_output_0' source:{-1,-1} target:{-1,-1,1}. Falling back to lenient merge.\n",
      "2024-11-10 06:35:59.211929 [W:onnxruntime:, coreml_execution_provider.cc:81 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 15 number of nodes in the graph: 430 number of nodes supported by CoreML: 299\n",
      "2024-11-10 06:36:00.478498 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2024-11-10 06:36:00.478519 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n",
      "2024-11-10 06:36:00.518929 [W:onnxruntime:, coreml_execution_provider.cc:81 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 4 number of nodes in the graph: 166 number of nodes supported by CoreML: 109\n",
      "2024-11-10 06:36:02.055773 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2024-11-10 06:36:02.055792 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import onnx\n",
    "\n",
    "model = onnx.load(\"models/sign/sign_yolo.onnx\")\n",
    "model.ir_version = 9\n",
    "onnx.save(model, \"models/sign/sign_yolo.onnx\")\n",
    "\n",
    "model = onnx.load(\"models/traffic-lights/traffic-lights.onnx\")\n",
    "model.ir_version = 9\n",
    "onnx.save(model, \"models/traffic-lights/traffic-lights.onnx\")\n",
    "\n",
    "model = onnx.load(\"models/twin_lite/pretrained/twin_lite.onnx\")\n",
    "model.ir_version = 9\n",
    "onnx.save(model, \"models/twin_lite/pretrained/twin_lite.onnx\")\n",
    "\n",
    "# Инициализация ONNX моделей\n",
    "# Степ, это нужно будет убрать\n",
    "# Либо посмотреть оптимизации для куды, чтобы быстрее было\n",
    "session_options = ort.SessionOptions()\n",
    "session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "session_options.intra_op_num_threads = 1\n",
    "session_options.inter_op_num_threads = 1\n",
    "\n",
    "# Здесь убрать sess_options=session_options, providers=[\"CoreMLExecutionProvider\"]\n",
    "# Либо посмотреть оптимизации для куды, чтобы быстрее было\n",
    "sign_model = ort.InferenceSession('models/sign/sign_yolo.onnx', sess_options=session_options, providers=[\"CoreMLExecutionProvider\"])\n",
    "traffic_lights_model = ort.InferenceSession('models/traffic-lights/traffic-lights.onnx', sess_options=session_options, providers=[\"CoreMLExecutionProvider\"])\n",
    "lane_model = ort.InferenceSession('models/twin_lite/pretrained/twin_lite.onnx', sess_options=session_options, providers=[\"CoreMLExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_video_length_in_seconds(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(\"Не удалось открыть видеофайл.\")\n",
    "\n",
    "    # Общее количество кадров\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # Частота кадров (FPS)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "\n",
    "    # Длина видео в секундах\n",
    "    video_length = frame_count / fps\n",
    "    return video_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ansamble_preprocessing import process_video\n",
    "from collections import defaultdict\n",
    "\n",
    "directory_path = \"videos/\"\n",
    "\n",
    "labels_dict = defaultdict()\n",
    "\n",
    "processed_files = dict()\n",
    "files_and_folders = os.listdir(directory_path)\n",
    "\n",
    "rename_files_in_table = {\n",
    "    \"akn00036\": \"akn00036_iXsAm22P.mov\",\n",
    "    \"akn00048\": \"AKN00048.mp4\",\n",
    "    \"akn00077\": \"AKN00077.mp4\",\n",
    "    \"akn00078\": \"AKN00078.mp4\",\n",
    "    \"akn00080\": \"akn00080_f9XXm8bV.mov\",\n",
    "    \"akn00085\": \"AKN00085.mp4\",\n",
    "    \"akn00047\": \"AKN00047.mp4\",\n",
    "    \"akn00088\": \"AKN00088.mp4\"\n",
    "}\n",
    "\n",
    "for id, row in df.iterrows():\n",
    "    for file_name in files_and_folders:\n",
    "        file_real = row['file']\n",
    "        if row['file'] in rename_files_in_table:\n",
    "            file_real = rename_files_in_table[row['file']]\n",
    "        if file_real in file_name:\n",
    "            video_path = os.path.join(directory_path, file_name)\n",
    "            if file_name not in processed_files:\n",
    "                processed_files[file_name] = process_video(video_path, sign_model, traffic_lights_model, lane_model)\n",
    "                \n",
    "            if row['file'] not in labels_dict:\n",
    "                labels_dict[file_name] = [0] * int(get_video_length_in_seconds(video_path))\n",
    "            labels_dict[file_name][row['sec']] = row['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['akn00006_fqGg6dtL.mov', 'akn00036_iXsAm22P.mov', 'AKN00048.mp4', 'AKN00077.mp4', 'AKN00078.mp4', 'akn00080_f9XXm8bV.mov', 'AKN00085.mp4', 'AKN00047.mp4', 'AKN00088.mp4'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/rd9mywh12msdrg5xk2zvrs480000gn/T/ipykernel_90771/1733897788.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  frames_tensor = torch.tensor(frames, dtype=torch.float32).permute(0, 3, 1, 2)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mПри выполнении кода в текущей ячейке или предыдущей ячейке ядро аварийно завершило работу. \n",
      "\u001b[1;31mПроверьте код в ячейках, чтобы определить возможную причину сбоя. \n",
      "\u001b[1;31mЩелкните <a href='https://aka.ms/vscodeJupyterKernelCrash'>здесь</a>, чтобы получить дополнительные сведения. \n",
      "\u001b[1;31mПодробнее см. в <a href='command:jupyter.viewOutput'>журнале Jupyter</a>."
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from classification_model import LightTrafficViolationClassifier, train_model, CustomViolationLoss\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class TrafficViolationDataset(Dataset):\n",
    "    def __init__(self, processed_files, labels_dict):\n",
    "        self.processed_files = processed_files\n",
    "        self.labels_dict = labels_dict\n",
    "        self.video_names = list(processed_files.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.video_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_name = self.video_names[idx]\n",
    "        frames = self.processed_files[video_name]  # цепочка обработанных кадров (размер [D, H, W, 3])\n",
    "        labels = self.labels_dict[video_name]      # список лейблов (размер D)\n",
    "        \n",
    "        # Преобразуем размерности кадров [D, H, W, 3] -> [D, 3, H, W]\n",
    "        frames_tensor = torch.tensor(frames, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        return frames_tensor, labels_tensor\n",
    "\n",
    "num_classes = len(set([label for labels in labels_dict.values() for label in labels]))\n",
    "\n",
    "# Подготовка данных и DataLoader\n",
    "video_names = list(processed_files.keys())\n",
    "train_videos, test_videos = train_test_split(video_names, test_size=0.2, random_state=42)\n",
    "train_dataset = TrafficViolationDataset({v: processed_files[v] for v in train_videos}, {v: labels_dict[v] for v in train_videos})\n",
    "val_dataset = TrafficViolationDataset({v: processed_files[v] for v in test_videos}, {v: labels_dict[v] for v in test_videos})\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Инициализация модели\n",
    "# Получаем размеры входных данных из loader\n",
    "sample_frames = next(iter(train_loader))[0]\n",
    "_, _, _, height, width = sample_frames.shape\n",
    "\n",
    "# Инициализация модели\n",
    "num_classes = len(set([label for labels in labels_dict.values() for label in labels]))\n",
    "model = LightTrafficViolationClassifier(\n",
    "    input_height=height,\n",
    "    input_width=width,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = CustomViolationLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "\n",
    "# Добавьте scheduling\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.3\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "train_model(\n",
    "    model, \n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=10,\n",
    "    validation_loader=val_loader,\n",
    "    window_size=5,\n",
    "    save_path='models/classification_model/cls_model.pth',\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Адаптированная функция для подсчета метрики с числовыми метками\n",
    "def pre_calc_score_numeric(gt, sub):\n",
    "    pred_seconds = []\n",
    "    correct_predictions = []\n",
    "    AE_count_rules_FP = []\n",
    "    AE_count_rules_FN = []\n",
    "\n",
    "    # Проходим по каждому нарушению из gt\n",
    "    for i, r_gt in gt.iterrows():\n",
    "        # Отбираем строки для конкретного видео и нарушения в сабмишене\n",
    "        video_sub = sub[(sub['номер видео'] == r_gt['номер видео']) & (sub['код нарушения'] == r_gt['код нарушения'])]\n",
    "        video_gt = gt[(gt['номер видео'] == r_gt['номер видео']) & (gt['код нарушения'] == r_gt['код нарушения'])]\n",
    "\n",
    "        # Если нарушения в предсказаниях отсутствуют\n",
    "        if len(video_sub) == 0:\n",
    "            pred_seconds.append(np.NaN)\n",
    "            correct_predictions.append(False)\n",
    "            FP = max(0 - len(video_gt), 0) # False Positive\n",
    "            FN = abs(min(0 - len(video_gt), 0)) # False Negative\n",
    "            AE_count_rules_FP.append(FP)\n",
    "            AE_count_rules_FN.append(FN)\n",
    "            continue\n",
    "\n",
    "        # Время реального нарушения\n",
    "        true_sec = r_gt['время нарушения (в секундах)']\n",
    "\n",
    "        # Находим ближайшую предсказанную секунду\n",
    "        pred_sec = min(video_sub['время нарушения (в секундах)'].values, key=lambda x: abs(x - true_sec))\n",
    "        pred_seconds.append(pred_sec)\n",
    "\n",
    "        # Проверяем попадание в 5-секундный интервал\n",
    "        correct_prediction = np.abs(pred_sec - true_sec) < 5\n",
    "        correct_predictions.append(correct_prediction)\n",
    "\n",
    "        # Подсчитываем FP и FN\n",
    "        FP = max(len(video_sub) - len(video_gt), 0)\n",
    "        FN = abs(min(len(video_sub) - len(video_gt), 0))\n",
    "        AE_count_rules_FP.append(FP)\n",
    "        AE_count_rules_FN.append(FN)\n",
    "\n",
    "    # Добавляем результаты в таблицу gt\n",
    "    gt['pred_seconds'] = pred_seconds\n",
    "    gt['Корректность предсказания'] = correct_predictions\n",
    "    gt['Лишние нарушения (FP)'] = AE_count_rules_FP\n",
    "    gt['Недостающие нарушения (FN)'] = AE_count_rules_FN\n",
    "    return gt\n",
    "\n",
    "# Функция для вычисления итоговой метрики\n",
    "def calculate_score(result_table):\n",
    "    return max(0, (result_table['Корректность предсказания'].sum() - (result_table['Лишние нарушения (FP)'].sum() * 0.5)) / len(result_table))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
